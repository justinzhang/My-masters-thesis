@misc{pawarSecureDSS,
      title={Securing Dynamic Distributed Storage Systems against Eavesdropping and Adversarial Attacks}, 
      author={Sameer Pawar and Salim El Rouayheb and Kannan Ramchandran},
      year={2011},
      eprint={1009.2556},
      archivePrefix={arXiv},
      primaryClass={cs.IT}
}

@misc{maturanaMergeBandwidth,
      title={Bandwidth Cost of Code Conversions in Distributed Storage: Fundamental Limits and Optimal Constructions}, 
      author={Francisco Maturana and K. V. Rashmi},
      year={2020},
      eprint={2008.12707},
      archivePrefix={arXiv},
      primaryClass={cs.IT}
}

@misc{maturanaSplitBandwidth,
      title={Bandwidth Cost of Code Conversions in the Split Regime}, 
      author={Francisco Maturana and K. V. Rashmi},
      year={2022},
      eprint={2205.06793},
      archivePrefix={arXiv},
      primaryClass={cs.IT}
}

@misc{maturanaAccessAll,
      title={Access-optimal Linear MDS Convertible Codes for All Parameters}, 
      author={Francisco Maturana and V. S. Chaitanya Mukka and K. V. Rashmi},
      year={2020},
      eprint={2006.03042},
      archivePrefix={arXiv},
      primaryClass={cs.IT}
}

@misc{maturanaAccessMerge,
      title={Convertible Codes: Efficient Conversion of Coded Data in Distributed Storage}, 
      author={Francisco Maturana and K. V. Rashmi},
      year={2019},
      eprint={1907.13119},
      archivePrefix={arXiv},
      primaryClass={cs.IT}
}

@misc{subramanianStaticWiretap,
      title={MDS codes on the erasure-erasure wiretap channel}, 
      author={Arunkumar Subramanian and Steven W. McLaughlin},
      year={2009},
      eprint={0902.3286},
      archivePrefix={arXiv},
      primaryClass={cs.IT}
}



@inproceedings {erasureCodingInAzure,
author = {Cheng Huang and Huseyin Simitci and Yikang Xu and Aaron Ogus and Brad Calder and Parikshit Gopalan and Jin Li and Sergey Yekhanin},
title = {Erasure Coding in Windows Azure Storage},
booktitle = {2012 USENIX Annual Technical Conference (USENIX ATC 12)},
year = {2012},
isbn = {978-931971-93-5},
address = {Boston, MA},
pages = {15--26},
url = {https://www.usenix.org/conference/atc12/technical-sessions/presentation/huang},
publisher = {USENIX Association},
month = jun
}

@article{googleFileSystem,
author = {Ghemawat, Sanjay and Gobioff, Howard and Leung, Shun-Tak},
title = {The Google file system},
year = {2003},
issue_date = {December 2003},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {37},
number = {5},
issn = {0163-5980},
url = {https://doi.org/10.1145/1165389.945450},
doi = {10.1145/1165389.945450},
journal = {SIGOPS Oper. Syst. Rev.},
month = {oct},
pages = {29–43},
numpages = {15},
keywords = {scalability, fault tolerance, data storage, clustered storage}
}


@inproceedings{Heart,
author = {Kadekodi, Saurabh and Rashmi, K. V. and Ganger, Gregory R.},
title = {Cluster storage systems gotta have HeART: improving storage efficiency by exploiting disk-reliability heterogeneity},
year = {2019},
isbn = {9781931971485},
publisher = {USENIX Association},
address = {USA},
abstract = {Large-scale cluster storage systems typically consist of a heterogeneous mix of storage devices with significantly varying failure rates. Despite such differences among devices, redundancy settings are generally configured in a one-scheme-for-all fashion. In this paper, we make a case for exploiting reliability heterogeneity to tailor redundancy settings to different device groups. We present HeART, an online tuning tool that guides selection of, and transitions between redundancy settings for long-term data reliability, based on observed reliability properties of each disk group. By processing disk failure data over time, HeART identifies the boundaries and steady-state failure rate for each deployed disk group (e.g., by make/model). Using this information, HeART suggests the most space-efficient redundancy option allowed that will achieve the specified target data reliability. Analysis of longitudinal failure data for a large production storage cluster shows the robustness of HeART's failure-rate determination algorithms. The same analysis shows that a storage system guided by HeART could provide target data reliability levels with fewer disks than one-scheme-for-all approaches: 11-16\% fewer compared to erasure codes like 10-of-14 or 6-of-9 and 33\% fewer compared to 3-way replication.},
booktitle = {Proceedings of the 17th USENIX Conference on File and Storage Technologies},
pages = {345–358},
numpages = {14},
location = {Boston, MA, USA},
series = {FAST'19}
}

